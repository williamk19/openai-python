{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI Completion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = dotenv_values(\".env\")[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "\tmodel=\"gpt-3.5-turbo-instruct\",\n",
    "\tprompt=\"Create a list of the top 10 most popular programming languages in 2022.\",\n",
    "\tmax_tokens=100,\n",
    "\tstop=[\"6.\"],\n",
    "\tn=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "1. Python\n",
      "2. Java\n",
      "3. JavaScript\n",
      "4. C++\n",
      "5. C#\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].finish_reason)\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Burj Khalifa in Dubai, standing at 828 meters, is the tallest building in the world.\n"
     ]
    }
   ],
   "source": [
    "reply = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the tallest building in the world and describe it less then 20 word?\",\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=50, # 1 to 4095 - The maximum number of tokens to generate\n",
    "    temperature=2, # 0 to 2 - Control the randomness of the output\n",
    "    top_p=0, # 0 to 1 - Control the diversity of the output\n",
    "    frequency_penalty=0, # 0 to 1 - Reduces the likelihood of selecting recently used tokens\n",
    "    presence_penalty=0, # 0 to 1 - Reduces the likelihood of selecting tokens that have already appeared in the text\n",
    ")\n",
    "\n",
    "print(reply.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "早上好，我的名字是威廉·库尔尼亚万 (Zǎoshang hǎo, wǒ de míngzi shì Wēilián Kù'ěrníyàwàn).\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = dotenv_values(\".env\")[\"OPENAI_API_KEY\"]\n",
    "\n",
    "reply = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are a helpful assistant that translates any language to Chinese with pinyin and also text to spell from one or more words with same or different language into one combined sentence in chinese.\n",
    "            Prompt: Translate 'I like' and 'tennis meja'.\n",
    "            Answer: 我喜欢乒乓球 (Wǒ xǐhuān pīngpāng qiú).\n",
    "            \"\"\",\n",
    "        },\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": \"Translate 'Good Morning' and 'nama saya william kurniawan'\"\n",
    "\t\t},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(reply.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
